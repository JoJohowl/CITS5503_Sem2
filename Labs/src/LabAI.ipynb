{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This tutorial is about tuning hyperparameters inside the jupyter notebook:\n",
    "\n",
    "Reviewed by: Zhi Zhang"
   ],
   "metadata": {},
   "id": "6fee3905233a00ac"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Objectives:\n",
    "<ul>\n",
    "<li>Get familiar with some common libraries for Data Analysis in Python such as Pandas.</li>\n",
    "<li>Get familiar with AWS SageMaker to train Machine Learning models using the cloud</li>\n",
    "<li>Get familiar with Jupyter Notebooks</li>\n",
    "</ul>"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T05:56:56.882445Z",
     "start_time": "2021-09-26T05:56:56.875737Z"
    }
   },
   "id": "e508e0aa5002e7c5"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Setup Environment Variables",
   "id": "5787ab77abf6b592"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "print(\"Please enter your AWS credentials for this lab. Your credentials are only used in this notebook session.\")\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = input('AWS_ACCESS_KEY_ID: ')\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = getpass('AWS_SECRET_ACCESS_KEY (hidden): ')\n",
    "os.environ['AWS_DEFAULT_REGION'] = input('AWS_DEFAULT_REGION: ') # e.g. us-west-2, us-east-1, etc."
   ],
   "id": "c1f4d3d6d9e595cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Verify your AWS credentials by running the following code. If your credentials are valid, you will see a message confirming that they are valid. If not, you will see an error message.",
   "id": "bcb3ca1d93902b2e"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import boto3\n",
    "try:\n",
    "    boto3.client('sts').get_caller_identity()\n",
    "    print(\"AWS credentials are valid.\")\n",
    "except Exception as e:\n",
    "    print(\"Invalid credentials. Please re-run the setup cell and check your input.\")\n",
    "    raise"
   ],
   "id": "ff75b0b5d64682f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Install libraries"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T05:55:12.580521Z",
     "start_time": "2021-09-26T05:55:12.578009Z"
    }
   },
   "id": "fc4578b0776978b6"
  },
  {
   "cell_type": "code",
   "source": [
    "# Install SageMaker via jupyter notebook\n",
    "!pip3 install sagemaker\n",
    "# Install pandas and numpy jupyter notebook\n",
    "!pip3 install pandas\n",
    "!pip3 install numpy"
   ],
   "metadata": {},
   "id": "23f465c1bfa9151",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prepare a SageMaker session"
   ],
   "metadata": {},
   "id": "d3e5f9f36e03f15"
  },
  {
   "cell_type": "code",
   "source": [
    "import sagemaker\n",
    "import numpy as np  # For matrix operations and numerical processing\n",
    "import pandas as pd  # For munging tabular data\n",
    "from time import gmtime, strftime\n",
    "\n",
    "smclient = boto3.Session().client(\"sagemaker\")\n",
    "sagemaker_role = \"arn:aws:iam::489389878001:role/SageMakerRole\"\n",
    "region = os.environ['AWS_DEFAULT_REGION']\n",
    "student_id = \"YOUR_STUDENTID\"  # use your student id\n",
    "bucket = \"YOUR_BUCKET_NAME\"  # use <studentid-lab8> as your bucket name\n",
    "prefix = f\"sagemaker/{student_id}-hpo-xgboost-dm\"\n",
    "\n",
    "s3_client = boto3.client(\"s3\")\n",
    "# Create a folder (prefix) in the bucket\n",
    "try:\n",
    "    s3_client.put_object(Bucket=bucket, Key=f\"{prefix}/\")\n",
    "    print(f\"Folder {prefix}/ created successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating folder: {e}\")"
   ],
   "metadata": {},
   "id": "efb3ab0f5092f48c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Update the code above as indicated by the comments:"
   ],
   "metadata": {},
   "id": "d157825d5c5cf24b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Download a dataset"
   ],
   "metadata": {},
   "id": "64ac239d0e9605ab"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Read and download the marketing dataset from UCI's ML Repository [here](https://archive.ics.uci.edu/ml/datasets/bank+marketing).\n",
    "\n",
    "NOTE: You can download and unzip the dataset using the commands below."
   ],
   "metadata": {},
   "id": "932b7e2a41e67de"
  },
  {
   "cell_type": "code",
   "source": [
    "!wget -N https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank-additional.zip\n",
    "!unzip -o bank-additional.zip"
   ],
   "metadata": {},
   "id": "132f39775b4228f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Read the dataset into a Pandas data frame and answer the following two questions:\n",
    "\n",
    "1. Which variables in the dataset are categorical? Give at least four variables.\n",
    "\n",
    "2. Which variables in the dataset are numerical? Give at least four variables."
   ],
   "metadata": {},
   "id": "ae5fd182ce194984"
  },
  {
   "cell_type": "code",
   "source": [
    "data = pd.read_csv(\"./bank-additional/bank-additional-full.csv\", sep=\";\")\n",
    "pd.set_option(\"display.max_columns\", 500)  # Make sure we can see all of the columns\n",
    "pd.set_option(\"display.max_rows\", 50)  # Keep the output on one page\n",
    "data"
   ],
   "metadata": {},
   "id": "9e974db761c2363e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Process the data by adding two new indicator columns and then expands categorical columns into binary dummy columns for modelling purposes."
   ],
   "metadata": {},
   "id": "8919689afcc0f759"
  },
  {
   "cell_type": "code",
   "source": [
    "data[\"no_previous_contact\"] = np.where(\n",
    "    data[\"pdays\"] == 999, 1, 0\n",
    ")  # Indicator variable to capture when pdays takes a value of 999\n",
    "data[\"not_working\"] = np.where(\n",
    "    np.in1d(data[\"job\"], [\"student\", \"retired\", \"unemployed\"]), 1, 0\n",
    ")  # Indicator for individuals not actively employed\n",
    "model_data = pd.get_dummies(data)  # Convert categorical variables to sets of indicators\n",
    "model_data = model_data.replace({'F': 0, 'T': 1, False: 0, True: 1})\n",
    "model_data"
   ],
   "metadata": {},
   "id": "2d8306376fa1dd11",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Remove the economic features and duration from our data as they would need to be forecasted with high precision to use as inputs in future predictions."
   ],
   "metadata": {},
   "id": "adef97831e5b0232"
  },
  {
   "cell_type": "code",
   "source": [
    "model_data = model_data.drop(\n",
    "    [\"duration\", \"emp.var.rate\", \"cons.price.idx\", \"cons.conf.idx\", \"euribor3m\", \"nr.employed\"],\n",
    "    axis=1,\n",
    ")"
   ],
   "metadata": {},
   "id": "977f2b18d3144051",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model_data"
   ],
   "metadata": {},
   "id": "4c6d2122d357d89f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Split the data into training, validation and test"
   ],
   "metadata": {},
   "id": "cd71edcd4a295d47"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We split the dataset into training (70%), validation (20%), and test (10%) datasets and convert the datasets to an appropriate format. We will use the training and validation datasets during training. Test dataset will be used to evaluate model performance after it is deployed to an endpoint.\n",
    "\n",
    "Amazon SageMaker's XGBoost algorithm expects data in the libSVM or CSV data format. In this lab, we use the CSV format. Note that the first column must be the target variable and the CSV should not include headers. Also, notice that although repetitive it's easier to do this after the train|validation|test split rather than before. This avoids any misalignment issues due to random reordering."
   ],
   "metadata": {},
   "id": "f439bcef0ca9aa54"
  },
  {
   "cell_type": "code",
   "source": [
    "train_data, validation_data, test_data = np.split(\n",
    "    model_data.sample(frac=1, random_state=1729),\n",
    "    [int(0.7 * len(model_data)), int(0.9 * len(model_data))],\n",
    ")\n",
    "\n",
    "pd.concat([train_data[\"y_yes\"], train_data.drop([\"y_no\", \"y_yes\"], axis=1)], axis=1).to_csv(\n",
    "    \"train.csv\", index=False, header=False\n",
    ")\n",
    "pd.concat(\n",
    "    [validation_data[\"y_yes\"], validation_data.drop([\"y_no\", \"y_yes\"], axis=1)], axis=1\n",
    ").to_csv(\"validation.csv\", index=False, header=False)\n",
    "pd.concat([test_data[\"y_yes\"], test_data.drop([\"y_no\", \"y_yes\"], axis=1)], axis=1).to_csv(\n",
    "    \"test.csv\", index=False, header=False\n",
    ")"
   ],
   "metadata": {},
   "id": "93d732e349a5a3bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Copy the file to the S3 bucket created earlier for Amazon SageMaker training to pick up."
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T05:50:57.122008Z",
     "start_time": "2021-09-26T05:50:57.118586Z"
    }
   },
   "id": "6744f4c451b7e284"
  },
  {
   "cell_type": "code",
   "source": [
    "boto3.Session().resource(\"s3\").Bucket(bucket).Object(\n",
    "    os.path.join(prefix, \"train/train.csv\")\n",
    ").upload_file(\"train.csv\")\n",
    "boto3.Session().resource(\"s3\").Bucket(bucket).Object(\n",
    "    os.path.join(prefix, \"validation/validation.csv\")\n",
    ").upload_file(\"validation.csv\")"
   ],
   "metadata": {},
   "id": "953ae0bf18c941b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Setup hyperparameter tuning"
   ],
   "metadata": {},
   "id": "637a4c434cc87238"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set up the the name and configuration for a hyperparameter tuning job."
   ],
   "metadata": {},
   "id": "a22b2a8c9765fbd9"
  },
  {
   "cell_type": "code",
   "source": [
    "from time import gmtime, strftime, sleep\n",
    "\n",
    "# Names have to be unique. You will get an error if you reuse the same name\n",
    "tuning_job_name = f\"{student_id}-xgboost-tuningjob-01\"\n",
    "\n",
    "print(tuning_job_name)\n",
    "\n",
    "tuning_job_config = {\n",
    "    \"ParameterRanges\": {\n",
    "        \"CategoricalParameterRanges\": [],\n",
    "        \"ContinuousParameterRanges\": [\n",
    "            {\n",
    "                \"MaxValue\": \"1\",\n",
    "                \"MinValue\": \"0\",\n",
    "                \"Name\": \"eta\",\n",
    "            },\n",
    "            {\n",
    "                \"MaxValue\": \"10\",\n",
    "                \"MinValue\": \"1\",\n",
    "                \"Name\": \"min_child_weight\",\n",
    "            },\n",
    "            {\n",
    "                \"MaxValue\": \"2\",\n",
    "                \"MinValue\": \"0\",\n",
    "                \"Name\": \"alpha\",\n",
    "            },\n",
    "        ],\n",
    "        \"IntegerParameterRanges\": [\n",
    "            {\n",
    "                \"MaxValue\": \"10\",\n",
    "                \"MinValue\": \"1\",\n",
    "                \"Name\": \"max_depth\",\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "    \"ResourceLimits\": {\"MaxNumberOfTrainingJobs\": 2, \"MaxParallelTrainingJobs\": 2},\n",
    "    \"Strategy\": \"Bayesian\",\n",
    "    \"HyperParameterTuningJobObjective\": {\"MetricName\": \"validation:auc\", \"Type\": \"Maximize\"},\n",
    "}"
   ],
   "metadata": {},
   "id": "beda7cfe451900d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Specify the XGBoost algorithm for subsequent tuning."
   ],
   "metadata": {},
   "id": "79615c73d1d06f79"
  },
  {
   "cell_type": "code",
   "source": [
    "from sagemaker.image_uris import retrieve\n",
    "# Use XGBoost algorithm for training\n",
    "training_image = retrieve(framework=\"xgboost\", region=region, version=\"latest\")\n",
    "\n",
    "s3_input_train = \"s3://{}/{}/train\".format(bucket, prefix)\n",
    "s3_input_validation = \"s3://{}/{}/validation/\".format(bucket, prefix)\n",
    "\n",
    "training_job_definition = {\n",
    "    \"AlgorithmSpecification\": {\"TrainingImage\": training_image, \"TrainingInputMode\": \"File\"},\n",
    "    \"InputDataConfig\": [\n",
    "        {\n",
    "            \"ChannelName\": \"train\",\n",
    "            \"CompressionType\": \"None\",\n",
    "            \"ContentType\": \"csv\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\",\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": s3_input_train,\n",
    "                }\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"ChannelName\": \"validation\",\n",
    "            \"CompressionType\": \"None\",\n",
    "            \"ContentType\": \"csv\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\",\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": s3_input_validation,\n",
    "                }\n",
    "            },\n",
    "        },\n",
    "    ],\n",
    "    \"OutputDataConfig\": {\"S3OutputPath\": \"s3://{}/{}/output\".format(bucket, prefix)},\n",
    "    \"ResourceConfig\": {\"InstanceCount\": 1, \"InstanceType\": \"ml.m5.xlarge\", \"VolumeSizeInGB\": 10},\n",
    "    \"RoleArn\": sagemaker_role,\n",
    "    \"StaticHyperParameters\": {\n",
    "        \"eval_metric\": \"auc\",\n",
    "        \"num_round\": \"1\",\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"rate_drop\": \"0.3\",\n",
    "        \"tweedie_variance_power\": \"1.4\",\n",
    "    },\n",
    "    \"StoppingCondition\": {\"MaxRuntimeInSeconds\": 43200},\n",
    "}"
   ],
   "metadata": {},
   "id": "458fdfc6ddb1334a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Launch the tuning job.",
   "id": "4208c362911001d3"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "",
   "id": "a5a61224490ec748",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Launch Hyperparameter Tuning Job\n",
    "smclient.create_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuning_job_name,\n",
    "    HyperParameterTuningJobConfig=tuning_job_config,\n",
    "    TrainingJobDefinition=training_job_definition,\n",
    ")"
   ],
   "id": "1439fedc00ad21",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to AWS console (SageMaker-> Training -> Hyperparameter tuning jobs) to monitor the progress of the hyperparameter tuning job ([How to monitor the progress of a job?](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-monitor.html)).\n",
    "The tuning will normally take between 2-4 minutes. Make ensure that the tuning job is completed successfully from the console. Also check the job output inside the s3 object you created. Last, remove all the AWS resources you used in this lab."
   ],
   "id": "3547fce6c6d6a342"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "",
   "id": "d85a45f9a4b0a611",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (ReadPssesion)",
   "language": "python",
   "name": "pycharm-8851adb6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
